{
    "os": "Linux-5.15.0-119-generic-x86_64-with-glibc2.31",
    "python": "3.9.19",
    "heartbeatAt": "2024-08-30T06:06:19.619863",
    "startedAt": "2024-08-30T06:06:18.902618",
    "docker": null,
    "cuda": null,
    "args": [
        "--model_id",
        "maywell/EXAONE-3.0-7.8B-Instruct-Llamafied",
        "--device",
        "cuda:0",
        "--epoch",
        "12",
        "--lr",
        "3e-5",
        "--batch_size",
        "1",
        "--wandb_project",
        "DCS_wandb",
        "--wandb_entity",
        "DCS_2024",
        "--wandb_run_name",
        "llama_3_model_chat_other_prompt",
        "--prompt_type",
        "mode_moon_co7",
        "--prompt",
        "\ub2f9\uc2e0\uc740 \uc720\ub2a5\ud55c AI \uc5b4\uc2dc\uc2a4\ud134\ud2b8\uc785\ub2c8\ub2e4. \uc8fc\uc5b4\uc9c4 \ub300\ud654\ub97c \uc790\uc138\ud788 \uc9d1\uc911\ud574\uc11c \uc77d\uace0 \ud1a0\ud53d\uc5d0 \uae30\ubc18\ud55c \ub300\ud654 \ub0b4\uc6a9\uc744 \uc694\uc57d\ud574\uc8fc\uc138\uc694. [speaker1], [speaker2]\ub85c \ud654\uc790\ub97c \uad6c\ubd84\ud569\ub2c8\ub2e4. \uac01 \ud654\uc790\uc758 \ubc1c\ud654\ub97c \uc815\ud655\ud788 \uad6c\ubd84\ud558\uace0, \uac01 \ud654\uc790\uac00 \uc81c\uc2dc\ud55c \uc758\uacac\uc744 \uac01\uc790 \uc815\ub9ac\ud558\uba70, \ub3d9\uc77c\ud55c \ub0b4\uc6a9\uc744 \ubc18\ubcf5\ud558\uc9c0 \uc54a\ub3c4\ub85d \uc8fc\uc758\ud558\uc2ed\uc2dc\uc624. \uac01 \ud654\uc790\uc758 \uc774\ub984\uacfc \uadf8\uc5d0 \ub530\ub978 \ub0b4\uc6a9\uc744 \uba85\ud655\ud788 \ub9e4\uce6d\ud558\uc5ec \uc694\uc57d\ud574 \uc8fc\uc138\uc694.",
        "--trainer",
        "True",
        "--gradient_accumulation_steps",
        "10"
    ],
    "state": "running",
    "program": "-m run.solar_train",
    "codePathLocal": null,
    "git": {
        "remote": "https://github.com/Hostoday/GCU_ISNLP_B.git",
        "commit": "605070fadb2b00f03e8e60b690e6fe867100ecef"
    },
    "email": "wjdghwns1096@gmail.com",
    "root": "/mnt/ssd2/jeong/GCU_ISNLP_B",
    "host": "nlplab-MS-7D27",
    "username": "nlplab",
    "executable": "/home/nlplab/anaconda3/envs/GCU_INSLP_B/bin/python",
    "cpu_count": 16,
    "cpu_count_logical": 24,
    "cpu_freq": {
        "current": 3100.68125,
        "min": 800.0,
        "max": 4716.666666666667
    },
    "cpu_freq_per_core": [
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5200.0
        },
        {
            "current": 1220.123,
            "min": 800.0,
            "max": 5200.0
        },
        {
            "current": 875.582,
            "min": 800.0,
            "max": 5200.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5200.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 5100.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 3900.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 3900.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 3900.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 3900.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 3900.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 3900.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 3900.0
        },
        {
            "current": 3200.0,
            "min": 800.0,
            "max": 3900.0
        }
    ],
    "disk": {
        "/": {
            "total": 795.1984329223633,
            "used": 671.2910232543945
        }
    },
    "gpu": "NVIDIA GeForce RTX 3090",
    "gpu_count": 3,
    "gpu_devices": [
        {
            "name": "NVIDIA GeForce RTX 3090",
            "memory_total": 25769803776
        },
        {
            "name": "NVIDIA GeForce RTX 3090",
            "memory_total": 25769803776
        },
        {
            "name": "NVIDIA GeForce RTX 3090",
            "memory_total": 25769803776
        }
    ],
    "memory": {
        "total": 125.58802795410156
    }
}
